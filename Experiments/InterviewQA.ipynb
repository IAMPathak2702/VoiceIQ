{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29624cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict , TypedDict , Optional\n",
    "from langgraph.graph import StateGraph , END\n",
    "import random\n",
    "import time\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser \n",
    "import os\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f7db9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    history: Optional[str]= None\n",
    "    result:Optional[str]= None\n",
    "    total_question:Optional[str]= None\n",
    "    interviewer:Optional[str]= None\n",
    "    candidate:Optional[str]= None\n",
    "    current_question:Optional[str]= None\n",
    "    current_answer:Optional[str]= None\n",
    "        \n",
    "workflow = StateGraph(GraphState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "607265b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_interviewer = \"You are a {}. You need to interview a {}. This is the interview so far:\\n{}\\n\\\n",
    "Ask your next question and donot repeat Question.\\\n",
    "Keep it less than 10 words and output just the question and no extra text\"\n",
    "\n",
    "prompt_interviewee = \"You are a {}. You have appeared for a job interview.\\\n",
    "Answer the question asked in very short in less than 10 words. Outputs Just the answer with no extra text.\\\n",
    "Question:{}\"\n",
    "\n",
    "prompt_result = \"\"\"\n",
    "Check weather the answer given for asked question is correct or not?\n",
    "Evaluate on a Scale of 10 and give a very sort (maximum 10 words) reason as well\n",
    "question:{}\\nanswer:{}\"\"\"\n",
    "\n",
    "prompt_verdict = \"\"\"Given the interview, should we select the candidate?\n",
    "Give output Yes or NO with a reason in less than 10 words\n",
    "the interview:{}\"\"\"\n",
    "\n",
    "prompt_cleanup = \"Remove empty dialogues , repeated sentences and repeted names to convert this input as conversation:\\n{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d348d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_question(state):\n",
    "    history = state.get(\"history\",\"\").strip()\n",
    "    role = state.get(\"interviewer\",\"\").strip()\n",
    "    candidate = state.get(\"candidate\",\"\").strip()\n",
    "    \n",
    "    \n",
    "    prompt = prompt_interviewer.format(role , candidate, history)\n",
    "    \n",
    "    print(prompt)\n",
    "    \n",
    "    question = role +\":\"+ llm(prompt)\n",
    "    \n",
    "    print(\"Question:\",question)\n",
    "    \n",
    "    if history ==\"Nothing\":\n",
    "        history= \"\"\n",
    "        \n",
    "    return {\"history\":history +\"\\n\" + question,\n",
    "           \"current_question\":question,\n",
    "           \"total_question\":state.get(\"total_questions\")+1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cb62e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_response(state, user_input):\n",
    "    history = state.get(\"history\",\"\").strip()\n",
    "    role = state.get(\"interviewer\",\"\").strip()\n",
    "    candidate = state.get(\"candidate\",\"\").strip()\n",
    "    \n",
    "    prompt = prompt_interviewee.format(candidate,question)\n",
    "    print(prompt)\n",
    "    \n",
    "    answer = candidate + \":\" + user_input\n",
    "    \n",
    "    print(\"Response:\",answer)\n",
    "    \n",
    "    return {\"history\":history +\"\\n\" + answer,\n",
    "           \"current_question\":answer}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c50c2c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_evaluate(state):\n",
    "    question = state.get(\"current_question\",\"\").strip()\n",
    "    answer = state.get(\"current_answer\",\"\").strip()\n",
    "    history = state.get(\"history\",\"\").strip()\n",
    "    \n",
    "    \n",
    "    prompt = prompt_result.format(question , answer)\n",
    "    evaluation = llm(prompt)\n",
    "    print(prompt)\n",
    "    \n",
    "    \n",
    "    print(\"Evaluation:\",evaluation)\n",
    "    \n",
    "    print(\"--------------DONE--------------\")\n",
    "    \n",
    "    return {\"history\":histroy}+\"\\n\"+evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6705e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_result(state):\n",
    "    history = state.get(\"history\",\"\").strip()\n",
    "    cleaned_up = llm(prompt_cleanup.format(history))\n",
    "    prompt = prompt_verdict.format(cleaned_up)\n",
    "    \n",
    "    result - llm(prompt)\n",
    "    \n",
    "    print(prompt)\n",
    "    \n",
    "    print(\"result:\",result)\n",
    "    \n",
    "    return{\"result\":result,\"histroy\":cleaned_up}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0a48b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"handle_question\",handle_question)\n",
    "workflow.add_node(\"handle_evaluate\",handle_evaluate)\n",
    "workflow.add_node(\"handle_response\",handle_response)\n",
    "workflow.add_node(\"handle_result\",handle_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dd1a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_conv_length(state):\n",
    "    return \"handle_question\" if state.get(\"total_question\")<3 else \"handle_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aecfc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_conditional_edges(\n",
    "\"handle_evaluate\",\n",
    "check_conv_length,\n",
    "{\n",
    "    \"handle_question\",\"handle_question\",\n",
    "    \"handle_evaluate\",\"handle_evaluate\",\n",
    "    \"handle_response\",\"handle_response\",\n",
    "    \"handle_result\",'handle_result',\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052950f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.set_entry_point(\"handle_question\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
